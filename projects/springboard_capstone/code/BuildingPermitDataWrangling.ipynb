{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predicting Building Permit Issuance Times for San Francisco?**\n",
    "##                                                                                             ...and answering many questions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T03:25:41.260358Z",
     "start_time": "2018-02-18T03:25:41.255344Z"
    }
   },
   "source": [
    "***A Data Science Project by Aparna Shastry***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "+ Introduction\n",
    "+ Data\n",
    "+ What Are We Trying to Find Out?\n",
    "+ Cleaning the Data\n",
    "+ Exploratory Data Analysis\n",
    "+ Drawing Inferences\n",
    "+ Identification of features\n",
    "+ Modeling\n",
    "+ Predicting\n",
    "+ Conclusions\n",
    "\n",
    "## Introduction\n",
    "A building permit is an official approval document issued by a governmental agency that allows you or your contractor to proceed with a construction or remodeling project on one's property. For more details click [here](https://www.thespruce.com/what-is-a-building-permit-1398344). Each city or county has its own office related to buildings, that can do multiple functions like issuing permits, inspecting buildings to enforce safety measures, modifying rules to accommodate needs of the growing population etc. For the city of San Francisco, permit issueing is taken care by [Permit Services wing of Department of Building Inspection](http://sfdbi.org/permit-services) (henceforth called DBI).\n",
    "The delays in permit issuance pose serious problems to construction industries and later on real estate agencies.Read this [Trulia study](https://www.trulia.com/blog/trends/elasticity-2016/) and [Vancouver city article](https://biv.com/article/2014/11/city-building-permit-delays-costing-developers-tim).\n",
    "\n",
    "## Data\n",
    "Data for this project is available in San Francisco city open data portal. It is updated every Saturday.\n",
    "1. Go to the link: [SF](https://data.sfgov.org/Housing-and-Buildings/Building-Permits/i98e-djp9/data) open portal. \n",
    "2. Click on Filter and \"Add a Filter Condition\".\n",
    "3. A drop down menu appears.\n",
    "4. Select, \"Filed Date\" and \"is after\".\n",
    "5. I entered date as 12/31/2012, because I wanted to do analysis of last 4-5 years. I think most recent data is important in matters such as this, the city council policies could change, there might be new rules, new employers to expedite process etc. Old data may not be too useful in modeling.\n",
    "6. I chose to download in CSV format because it is of the less than 100MB size and easy to load into notebook. If it gave issues, I might have chosen a different format.\n",
    "\n",
    "The file as of Feb 25, 2018 (Sunday) has been downloaded and kept for easy access. Size is about 75MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Are We Trying to Find Out?\n",
    "\n",
    "Primary Objective of this project is to model the building permit issuance times using at least last 3 years of permit filing/issuing data, so that this model can be used to predict the permit issuance times for the applications filed in future. Apart from that, this work will address a few concerns/answers a few questions which are of help in practical life in construction industry. We will get to the specifics once we get initial glimpse of columns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T03:02:49.201132Z",
     "start_time": "2018-02-20T03:02:41.652462Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aparn\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "C:\\Users\\Aparn\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(style='white')\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T03:09:01.572569Z",
     "start_time": "2018-02-20T03:03:02.666085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 198900 entries, 0 to 198899\n",
      "Data columns (total 43 columns):\n",
      "Permit Number                             198900 non-null object\n",
      "Permit Type                               198900 non-null int64\n",
      "Permit Type Definition                    198900 non-null object\n",
      "Permit Creation Date                      198900 non-null object\n",
      "Block                                     198900 non-null object\n",
      "Lot                                       198900 non-null object\n",
      "Street Number                             198900 non-null int64\n",
      "Street Number Suffix                      2216 non-null object\n",
      "Street Name                               198900 non-null object\n",
      "Street Suffix                             196132 non-null object\n",
      "Unit                                      29479 non-null float64\n",
      "Unit Suffix                               1961 non-null object\n",
      "Description                               198610 non-null object\n",
      "Current Status                            198900 non-null object\n",
      "Current Status Date                       198900 non-null object\n",
      "Filed Date                                198900 non-null object\n",
      "Issued Date                               183960 non-null object\n",
      "Completed Date                            97191 non-null object\n",
      "First Construction Document Date          183954 non-null object\n",
      "Structural Notification                   6922 non-null object\n",
      "Number of Existing Stories                156116 non-null float64\n",
      "Number of Proposed Stories                156032 non-null float64\n",
      "Voluntary Soft-Story Retrofit             35 non-null object\n",
      "Fire Only Permit                          18827 non-null object\n",
      "Permit Expiration Date                    147020 non-null object\n",
      "Estimated Cost                            160834 non-null float64\n",
      "Revised Cost                              192834 non-null float64\n",
      "Existing Use                              157786 non-null object\n",
      "Existing Units                            147362 non-null float64\n",
      "Proposed Use                              156461 non-null object\n",
      "Proposed Units                            147989 non-null float64\n",
      "Plansets                                  161591 non-null float64\n",
      "TIDF Compliance                           2 non-null object\n",
      "Existing Construction Type                155534 non-null float64\n",
      "Existing Construction Type Description    155534 non-null object\n",
      "Proposed Construction Type                155738 non-null float64\n",
      "Proposed Construction Type Description    155738 non-null object\n",
      "Site Permit                               5359 non-null object\n",
      "Supervisor District                       197183 non-null float64\n",
      "Neighborhoods - Analysis Boundaries       197175 non-null object\n",
      "Zipcode                                   197184 non-null float64\n",
      "Location                                  197200 non-null object\n",
      "Record ID                                 198900 non-null int64\n",
      "dtypes: float64(12), int64(3), object(28)\n",
      "memory usage: 65.3+ MB\n",
      "Wall time: 3.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read and make a copy for speed\n",
    "sf = pd.read_csv('../data/Building_Permits.csv',low_memory=False)\n",
    "sf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are We Trying to Find Out (Continued):\n",
    "\n",
    "Specifically, we will be trying to answer the following in the next parts:\n",
    "\n",
    "+ **Data Cleaning:**      \n",
    "1) Which of these columns we should retain for further analysis? This is the first question to answer because eliminating obviously non-useful columns would save lot of time.        \n",
    "2) How to interpret the records with zero or very small values for cost variables related to the construction?                \n",
    "3) What to do we do if dates map to Saturday or Sunday? A date having invalid numbers for month and day of the month?      \n",
    "4) Should we replace blanks in some columns where the valid value is 'Y'?       \n",
    "         \n",
    "+ **Exploratory Data Analysis:**   \n",
    "1) What is the best day of the week to visit DBI, to file an application form? Is the popular belief “mid-week (Wednesday) is the least crowded and hence best to visit government or city agencies” true in this case?    \n",
    "2) What type of permits are mostly issued on the same day of filing?     \n",
    "3) Which types take least average time issue if not issued on the same day?    \n",
    "4) Is there any particular quarter of each year which has higher application counts or average wait times? Can it be justified from the business knowledge?    \n",
    "5) Is the “Revised Cost” of a construction always more than “Estimated Cost”?     \n",
    "6) Is there a correlation between the location and wait times?     \n",
    "\n",
    "+ **Drawing Inferences:**         \n",
    "1) Is there a statistically significant difference between issuance times for Residential Vs Commercial buildings?             \n",
    "2) Is there a statistically significant difference between wait times of fire only permits and not fire only permits? Similarly with site permit. What is the interpretation?     \n",
    "3) Is there a statistically significant difference in wait time for high cost and low cost projects\n",
    "4) Can we do Anova test to verify variability across years in wait times, or variability in issue dates across weekdays        \n",
    "\n",
    "+ **Modeling:**     \n",
    "1) What are the main factors influencing the building permit issuance times?         \n",
    "2) How does the building estimated cost relate to wait times?         \n",
    "\n",
    "+ **Predicting:**      \n",
    "1) Predict the time to issue from  the date of filing, based on the model chosen in modeling stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to datetime\n",
    "import traceback\n",
    "try :\n",
    "    sf['Filed Date'] = pd.to_datetime(sf['Filed Date'],errors='coerce')\n",
    "    sf['Issued Date'] = pd.to_datetime(sf['Issued Date'],errors='coerce')\n",
    "    sf['Permit Expiration Date'] = pd.to_datetime(sf['Permit Expiration Date'],errors='coerce')\n",
    "except :    \n",
    "    traceback.print_exc()\n",
    "\n",
    "# Keep a copy to reload\n",
    "sfcpy = sf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T03:09:01.964969Z",
     "start_time": "2018-02-20T03:09:01.574935Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sometimes when re-run is required, one can start from just here, to save time\n",
    "sf = sfcpy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename for brevity/readability\n",
    "sf = sf.rename(columns =   {'Neighborhoods - Analysis Boundaries':'neighborhoods',\n",
    "                            'Permit Type' : 'perm_typ',\n",
    "                            'Permit Type Definition': 'perm_typ_def',\n",
    "                            'Filed Date':'file_dt',\n",
    "                            'Issued Date':'issue_dt',\n",
    "                            'Permit Expiration Date' : 'perm_exp_dt',\n",
    "                            'Structural Notification':'strct_notif',\n",
    "                            'Number of Existing Stories':'no_exist_stry',\n",
    "                            'Number of Proposed Stories':'no_prop_stry',\n",
    "                            'Fire Only Permit':'fire_only_permit',\n",
    "                            'Estimated Cost':'est_cost',\n",
    "                            'Revised Cost':'rev_cost',\n",
    "                            'Existing Use':'exist_use',\n",
    "                            'Proposed Use': 'prop_use',\n",
    "                            'Plansets':'plansets',\n",
    "                            'Existing Construction Type': 'exist_const_type',\n",
    "                            'Existing Construction Type Description': 'exist_const_type_descr',\n",
    "                            'Proposed Construction Type': 'prop_const_type',\n",
    "                            'Proposed Construction Type Description': 'prop_const_type_descr',\n",
    "                            'Site Permit':'site_permit',\n",
    "                            'Supervisor District':'sup_dist',\n",
    "                            'Location':'location'\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Permit Number', 'perm_typ', 'perm_typ_def', 'Permit Creation Date',\n",
       "       'Block', 'Lot', 'Street Number', 'Street Number Suffix', 'Street Name',\n",
       "       'Street Suffix', 'Unit', 'Unit Suffix', 'Description', 'Current Status',\n",
       "       'Current Status Date', 'file_dt', 'issue_dt', 'Completed Date',\n",
       "       'First Construction Document Date', 'strct_notif', 'no_exist_stry',\n",
       "       'no_prop_stry', 'Voluntary Soft-Story Retrofit', 'fire_only_permit',\n",
       "       'perm_exp_dt', 'est_cost', 'rev_cost', 'exist_use', 'Existing Units',\n",
       "       'prop_use', 'Proposed Units', 'plansets', 'TIDF Compliance',\n",
       "       'exist_const_type', 'exist_const_type_descr', 'prop_const_type',\n",
       "       'prop_const_type_descr', 'site_permit', 'sup_dist', 'neighborhoods',\n",
       "       'Zipcode', 'location', 'Record ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data\n",
    "\n",
    "The Tricky part of Data Wrangling in my knowledge so far,   \n",
    "\n",
    "a) Knowing what is present in the 'null' cells, is it NaN or simply ' '     \n",
    "b) In the non-null cells, if the all values are meaningful       \n",
    "c) Recognizing that even if a column has all non-null and meaningful values, the future updates to the column may have problems. Hence need to expect it and handle it      \n",
    "d) See the data and think if certain value make sense for the business and decide to drop those which are not relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answering the questions:\n",
    "1) The following columns are retained for further analysis. More could be added after discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr = sf[['perm_typ','file_dt','issue_dt','perm_exp_dt','strct_notif','no_exist_stry','no_prop_stry','fire_only_permit','est_cost','rev_cost',\n",
    "          'exist_use','prop_use','plansets','exist_const_type','prop_const_type','site_permit','neighborhoods',\n",
    "          'sup_dist','location']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Cost of the project is an essential part of the application according to [this post](http://www.herald-journal.com/housing/pages/older/permit.html). Hence if any of the 2 cost related columns have 0 or unusually small numbers, the best option is to drop those rows. Those are outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop too small values, we choose threshold 10. This is subjective. Could drop more in EDA.\n",
    "sfr = sfr.loc[sfr['est_cost'] > 10,:]\n",
    "sfr = sfr.loc[sfr['rev_cost'] > 10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) I would attribute it to typing mistake and make it previous or next day respectively. This may not be accurate, however it will not show a weekend in the EDA part.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr['file_day'] = sfr['file_dt'].dt.weekday_name\n",
    "sfr['issue_day'] = sfr['issue_dt'].dt.weekday_name\n",
    "sfr.loc[sfr['file_day']=='Saturday','file_dt']  = sfr.loc[sfr['file_day']=='Saturday','file_dt'] - datetime.timedelta(1)\n",
    "sfr.loc[sfr['file_day']=='Saturday','file_day'] = 'Friday'\n",
    "sfr.loc[sfr['file_day']=='Sunday','file_dt'] =  sfr.loc[sfr['file_day']=='Sunday','file_dt'] + datetime.timedelta(1)\n",
    "sfr.loc[sfr['file_day']=='Sunday','file_day'] = 'Monday'\n",
    "sfr.loc[sfr['issue_day']=='Saturday','issue_dt'] = sfr.loc[sfr['issue_day']=='Saturday','issue_dt'] - datetime.timedelta(1)\n",
    "sfr.loc[sfr['issue_day']=='Saturday','issue_day'] = 'Friday'\n",
    "sfr.loc[sfr['issue_day']=='Sunday','issue_dt'] = sfr.loc[sfr['issue_day']=='Sunday','issue_dt'] + datetime.timedelta(1)\n",
    "sfr.loc[sfr['issue_day']=='Sunday','issue_day'] = 'Monday'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) In the application forms (both physical or online), normally the applicant is supposed to tick the option if applicable. Otherwise nothing needs to be done. Hence it is understandable that blanks mean not applicable, a \"No\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill na with N. because in building permit databases, this is ticked if yes and left blank if it is not applicable\n",
    "sfr['fire_only_permit'].fillna('N',inplace=True)\n",
    "sfr['site_permit'].fillna('N',inplace=True)\n",
    "sfr['strct_notif'].fillna('N',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr['time_taken'] = (sfr['issue_dt'] - sfr['file_dt']).dt.days\n",
    "sfr['valid_period'] = (sfr['perm_exp_dt'] - sfr['issue_dt']).dt.days\n",
    "\n",
    "# We are interested in only finished ones for prediction of time\n",
    "sfr = sfr[sfr['time_taken'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr['month'] = sfr['file_dt'].dt.month\n",
    "sfr['year'] = sfr['file_dt'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need to check for validity in month or days because otherwise datatime conversion would have failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill nans in construction types with categorical numbers\n",
    "sfr.exist_const_type.fillna(9,inplace=True)\n",
    "sfr.prop_const_type.fillna(9,inplace=True)\n",
    "\n",
    "# Number of story: nans into a categorical representative number\n",
    "sfr.no_exist_stry.fillna(200,inplace=True)\n",
    "sfr.no_prop_stry.fillna(200,inplace=True)\n",
    "\n",
    "# Make Nan's into category number for plansets\n",
    "sfr.plansets = sfr.plansets.fillna(10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill location unknowns with 0's to indicate, it is unknown\n",
    "sfr.location.fillna('(0,0)',inplace=True)\n",
    "\n",
    "#Convert to float\n",
    "sfr.location = sfr.location.apply(lambda x: np.array([float((str(x).split('(')[1]).split(',')[0]),float((str(x).split('(')[1]).split(',')[1].split(')')[0])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace nans with strings \"Unknown\"\n",
    "sfr.exist_use.fillna('Unknown',inplace=True)\n",
    "sfr.prop_use.fillna('Unknown',inplace=True)\n",
    "\n",
    "# Some more variables\n",
    "sfr.neighborhoods.fillna('Unknown',inplace=True)\n",
    "sfr.sup_dist.fillna('Unknown',inplace=True)\n",
    "\n",
    "# Taking care to ensure that future data will not have Nans\n",
    "# Currently none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 130636 entries, 0 to 198896\n",
      "Data columns (total 25 columns):\n",
      "perm_typ            130636 non-null int64\n",
      "file_dt             130636 non-null datetime64[ns]\n",
      "issue_dt            130636 non-null datetime64[ns]\n",
      "perm_exp_dt         130635 non-null datetime64[ns]\n",
      "strct_notif         130636 non-null object\n",
      "no_exist_stry       130636 non-null float64\n",
      "no_prop_stry        130636 non-null float64\n",
      "fire_only_permit    130636 non-null object\n",
      "est_cost            130636 non-null float64\n",
      "rev_cost            130636 non-null float64\n",
      "exist_use           130636 non-null object\n",
      "prop_use            130636 non-null object\n",
      "plansets            130636 non-null int32\n",
      "exist_const_type    130636 non-null float64\n",
      "prop_const_type     130636 non-null float64\n",
      "site_permit         130636 non-null object\n",
      "neighborhoods       130636 non-null object\n",
      "sup_dist            130636 non-null object\n",
      "location            130636 non-null object\n",
      "file_day            130636 non-null object\n",
      "issue_day           130636 non-null object\n",
      "time_taken          130636 non-null float64\n",
      "valid_period        130635 non-null float64\n",
      "month               130636 non-null int64\n",
      "year                130636 non-null int64\n",
      "dtypes: datetime64[ns](3), float64(8), int32(1), int64(3), object(10)\n",
      "memory usage: 25.4+ MB\n"
     ]
    }
   ],
   "source": [
    "sfr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clean file\n",
    "sfr.to_csv('../data/building_permit_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments on the Data Wrangling: All essential variables for predicting wait times are cleaned up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
